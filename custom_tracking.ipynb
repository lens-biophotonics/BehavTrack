{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb418b4",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook refines YOLO video predictions into **tracked identities** across frames. It applies identity assignment, interpolation, and visualization to produce continuous trajectories for each mouse.\n",
    "\n",
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e72530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import (\n",
    "    get_video_resolution,\n",
    "    get_nb_frames,\n",
    "    save_metadata,\n",
    "    track,\n",
    "    overlay_annotations_on_video,\n",
    "    get_yolo_vid_detections_in_json\n",
    ")\n",
    "\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, Any, List\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ba632",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea175f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_predictions_dir = \"\"\n",
    "pre_processed_vids_path = \"\"\n",
    "output_dir = \"\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf93283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex to extract trailing frame index from filenames like \"..._123.txt\"\n",
    "frame_idx_regex = re.compile(r\"(\\d+)\\.txt$\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all pre-processed videos\n",
    "for pp_video_name in tqdm(os.listdir(pre_processed_vids_path), desc=\"Pre-Processed Videos\"):\n",
    "\n",
    "    # Skip files that are not videos\n",
    "    if not pp_video_name.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    # Path to the current pre-processed video\n",
    "    pp_video_path = os.path.join(pre_processed_vids_path, pp_video_name)\n",
    "\n",
    "    # Title = filename without extension (used for folder names etc.)\n",
    "    video_title = pp_video_name.replace(\".mp4\", \"\")\n",
    "\n",
    "    # YOLO predictions are expected in Ultralytics format:\n",
    "    #   <yolo_predictions_dir>/<video_title>/labels/*.txt\n",
    "    video_predicted_labels_path = os.path.join(\n",
    "        yolo_predictions_dir, f\"{video_title}/labels\"\n",
    "    )\n",
    "    if not os.path.isdir(video_predicted_labels_path):\n",
    "        print(f\"Missing labels dir for {pp_video_name}: {video_predicted_labels_path}\")\n",
    "        continue\n",
    "\n",
    "    # Output folder for this video (to save metadata + overlay video)\n",
    "    output_tracked_video_path = os.path.join(output_dir, video_title)\n",
    "    os.makedirs(output_tracked_video_path, exist_ok=True)\n",
    "\n",
    "    # --- Video properties ---\n",
    "    video_width, video_height = get_video_resolution(pp_video_path)\n",
    "    if video_width is None or video_height is None:\n",
    "        print(f\"Could not get resolution for {pp_video_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    nb_frames = get_nb_frames(pp_video_path)\n",
    "    if nb_frames is None or nb_frames == 0:\n",
    "        print(f\"Could not get number of frames for {pp_video_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # --- Collect detections ---\n",
    "    detections: Dict[str, Any] = {}\n",
    "    visible_percentage = 0.85\n",
    "    keypoint_names: List[str] = [\"nose\", \"earL\", \"earR\", \"tailB\"]\n",
    "\n",
    "    # Parse YOLO .txt labels into JSON-format detections\n",
    "    detections = get_yolo_vid_detections_in_json(\n",
    "        video_name=pp_video_name,\n",
    "        video_predicted_labels_path=video_predicted_labels_path,\n",
    "        frame_idx_regex=frame_idx_regex,        # regex for extracting frame indices\n",
    "        video_width=video_width,\n",
    "        video_height=video_height,\n",
    "        detections=detections,                  # dict to populate\n",
    "        visible_percentage=visible_percentage,  # threshold for visible keypoints\n",
    "        keypoint_names=keypoint_names\n",
    "    )\n",
    "    if not detections or len(detections) == 0:\n",
    "        print(f\"No detections for {pp_video_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(\n",
    "        f\"Found {len(detections)} frames with detections for {pp_video_name}. \"\n",
    "        f\"Saving detections under 'yolo_detections.json' at {output_tracked_video_path}\"\n",
    "    )\n",
    "    save_metadata(\n",
    "        output_dir=output_tracked_video_path,\n",
    "        metadata_filename=\"yolo_detections.json\",\n",
    "        metadata=detections\n",
    "    )\n",
    "\n",
    "    # --- Tracking parameters ---\n",
    "    params = dict(\n",
    "        vid_name=pp_video_name,\n",
    "        nb_fames=nb_frames,\n",
    "        detections=detections,\n",
    "        frames_skip_limit=30,\n",
    "        scale_factor=0.15,\n",
    "        penalty_per_missing=100,\n",
    "        abs_w=video_width,\n",
    "        abs_h=video_height,\n",
    "        alpha=0.75,\n",
    "        epsilon=1e-6,\n",
    "        cost_threshold=-0.05,\n",
    "        release_id_at_value=61,\n",
    "        max_ids=5\n",
    "    )\n",
    "\n",
    "    # Perform ID tracking across frames\n",
    "    custom_tracked_detections = track(**params)\n",
    "    if not custom_tracked_detections or len(custom_tracked_detections) == 0:\n",
    "        print(f\"Tracking failed for {pp_video_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Save tracked detections\n",
    "    save_metadata(\n",
    "        output_dir=output_tracked_video_path,\n",
    "        metadata_filename=\"custom_tracked_yolo_detections.json\",\n",
    "        metadata=custom_tracked_detections\n",
    "    )\n",
    "\n",
    "    # --- Overlay tracked detections on video ---\n",
    "    overlay_video_path = os.path.join(output_tracked_video_path, f\"{video_title}_tracked.mp4\")\n",
    "\n",
    "    # Color mappings for bounding boxes and keypoints\n",
    "    color_bbox = {\n",
    "        \"1\": (0, 0, 255),\n",
    "        \"2\": (0, 191, 255),\n",
    "        \"3\": (0, 255, 0),\n",
    "        \"4\": (255, 255, 0),\n",
    "        \"5\": (255, 0, 191),\n",
    "    }\n",
    "    color_kpts = {\n",
    "        \"nose\":  (0, 255, 255),\n",
    "        \"earL\":  (255, 102, 102),\n",
    "        \"earR\":  (140, 102, 255),\n",
    "        \"tailB\": (0, 128, 255),\n",
    "    }\n",
    "    discard = (False, [])  # (enable_flag, [ids_to_skip])\n",
    "\n",
    "    # Save overlay video with bounding boxes + keypoints\n",
    "    overlay_annotations_on_video(\n",
    "        input_video=pp_video_path,\n",
    "        annotations=custom_tracked_detections,\n",
    "        color_bbox=color_bbox,\n",
    "        color_kpts=color_kpts,\n",
    "        output_video=overlay_video_path,\n",
    "        discard=discard\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BehavTrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
