{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f0424a1",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook merges YOLO predictions with manual annotations into a unified dataset. Corrected predictions are added to the training pool for subsequent cycles.\n",
    "\n",
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import (\n",
    "    load_metadata,\n",
    "    copy_frames,\n",
    "    get_image_size,\n",
    "    yolo_txt_to_annotation_json,\n",
    "    save_metadata\n",
    ")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2b0f9",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62de4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"\"\n",
    "al_dir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dir = os.path.join(al_dir, \"predict\")\n",
    "\n",
    "annotations_dir = os.path.join(al_dir, \"annotations\")\n",
    "annotations_json = \"annotation.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine metadata for copying frames\n",
    "predict_metadata = load_metadata(\n",
    "    source_dir=al_dir,\n",
    "    metadata_filename=\"predict.json\"\n",
    ")\n",
    "\n",
    "manual_annotation_metadata = load_metadata(\n",
    "    source_dir=al_dir,\n",
    "    metadata_filename=\"annotations_metadata.json\"\n",
    ")\n",
    "\n",
    "# combine lists\n",
    "manual_annotation_metadata.extend(predict_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5202293",
   "metadata": {},
   "source": [
    "#### Copy frames referenced in combined annotation metadata into activeLearning_dir/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_data_combine = (\n",
    "    (\"annotations\", \"annotations_metadata.json\"),\n",
    "    (manual_annotation_metadata, True),\n",
    "    (source_dir, al_dir),\n",
    ")\n",
    "\n",
    "copy_frames(\n",
    "    split=split_data_combine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6832820",
   "metadata": {},
   "source": [
    "#### Load the current manual annotations JSON (will add predictions into it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_annotation_json_metadata = load_metadata(\n",
    "    source_dir=annotations_dir,\n",
    "    metadata_filename=annotations_json\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a9e9c",
   "metadata": {},
   "source": [
    "#### Convert YOLO .txt predictions in predict_dir into internal JSON annotation entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be483e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_annotated_flag = False\n",
    "visible_percentage = 0.90\n",
    "keypoint_names = [\"nose\", \"earL\", \"earR\", \"tailB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48560bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over prediction label files in predict_dir\n",
    "for label in os.listdir(predict_dir):\n",
    "    if label.endswith(\".txt\"):\n",
    "        label_path = os.path.join(predict_dir, label)\n",
    "\n",
    "        # Find corresponding image filename by swapping extension\n",
    "        image_name = label[:-4] + \".jpg\"  # strictly replace '.txt' â†’ '.jpg'\n",
    "\n",
    "        img_path = os.path.join(predict_dir, image_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            # If the matching image isn't present, skip gracefully\n",
    "            continue\n",
    "\n",
    "        img_w, img_h = get_image_size(image_path=img_path)\n",
    "\n",
    "        preds = yolo_txt_to_annotation_json(\n",
    "            txt_path=label_path,\n",
    "            image_filename=image_name,\n",
    "            image_width=img_w,\n",
    "            image_height=img_h,\n",
    "            manually_annotated_flag=manually_annotated_flag,\n",
    "            visible_percentage=visible_percentage,\n",
    "            keypoint_names=keypoint_names,\n",
    "        )\n",
    "\n",
    "        # Merge predictions for this image into the combined JSON\n",
    "        # (update will add new key or overwrite existing with new list)\n",
    "        if image_name in manual_annotation_json_metadata:\n",
    "            manual_annotation_json_metadata[image_name].extend(\n",
    "                preds.get(image_name, [])\n",
    "            )\n",
    "        else:\n",
    "            manual_annotation_json_metadata.update(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated combined annotations\n",
    "save_metadata(\n",
    "    output_dir=annotations_dir, \n",
    "    metadata_filename=\"annotation.json\", \n",
    "    metadata=manual_annotation_json_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013acb4",
   "metadata": {},
   "source": [
    "Back to step 5 [`/al_s5_p1(post-training)_anno-vs-al_split.ipynb`](/al_s5_p1(post-training)_anno-vs-al_split.ipynb), if the desired results are not there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BehavTrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
